{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utility import jaccard as jac_np\n",
    "from utility import point_form as pf_np\n",
    "from utility import intersect as int_np\n",
    "\n",
    "from box_utils  import jaccard as jac_torch\n",
    "from box_utils  import point_form as pf_torch\n",
    "from box_utils  import intersect  as int_torch \n",
    "\n",
    "from CustomDataLoaderTesting import DataAugmentor\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from SSD_generate_anchors import generate_ssd_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSDBoxSizes = collections.namedtuple('SSDBoxSizes', ['min', 'max'])\n",
    "\n",
    "Spec = collections.namedtuple('Spec', ['feature_map_size', 'shrinkage', 'box_sizes', \n",
    "                                       'aspect_ratios'])\n",
    "\n",
    "# the SSD orignal specs\n",
    "specs = [\n",
    "    Spec(38, 8, SSDBoxSizes(30, 60), [2]),\n",
    "    Spec(19, 16, SSDBoxSizes(60, 111), [2, 3]),\n",
    "    Spec(10, 32, SSDBoxSizes(111, 162), [2, 3]),\n",
    "    Spec(5, 64, SSDBoxSizes(162, 213), [2, 3]),\n",
    "    Spec(3, 100, SSDBoxSizes(213, 264), [2]),\n",
    "    Spec(1, 300, SSDBoxSizes(264, 315), [2])\n",
    "]\n",
    "\n",
    "priors = generate_ssd_priors(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = Path.home()/'data'/'VOCdevkit'/'VOC2007'\n",
    "root   = Path.home()/'Documents'/'DATASETS'/'VOCdevkit'/'VOC2007'\n",
    "voc_image_path      = root/'JPEGImages'\n",
    "voc_annotation_path = root/'Annotations'\n",
    "voc_trainval_path   = root/'ImageSets'/'Main'/'train.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flow_from_directory() got an unexpected keyword argument 'data_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f6b77c198222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                        \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                        \u001b[0mbatch_size\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                        shuffle = True)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: flow_from_directory() got an unexpected keyword argument 'data_file'"
     ]
    }
   ],
   "source": [
    "tester = DataAugmentor()\n",
    "generator = tester.flow_from_directory(root        = root,\n",
    "                                       data_file   = voc_trainval_path,\n",
    "                                       target_size = 300,\n",
    "                                       batch_size  = 1,\n",
    "                                       shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , target = generator[0]\n",
    "\n",
    "conf_data = target[0][:,0]\n",
    "loc_data  = target[0][:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loc_data_np = pf_np(loc_data)                    # point form numpy \n",
    "priors_np   = pf_np(priors).astype(np.float32)   # point form numpy\n",
    "\n",
    "print(loc_data)\n",
    "print(loc_data_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loc_data_th = torch.from_numpy(loc_data)\n",
    "conf_data_th   = torch.from_numpy(conf_data)\n",
    "\n",
    "priors_th   = torch.from_numpy(priors_np).float()\n",
    "\n",
    "loc_data_th_pf = pf_torch(loc_data_th) # point from in torch\n",
    "\n",
    "\n",
    "# print(loc_data_th)\n",
    "# print(loc_data_th_pf)\n",
    "print(conf_data)\n",
    "print(conf_data_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data_th.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_np = jac_np(box_a = loc_data_np, box_b = priors_np)\n",
    "iou_th = jac_torch(box_a = loc_data_th_pf, box_b= priors_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (iou_np == iou_th.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_np(matched = None, priors = None, variances = [0.1, 0.2]):\n",
    "    '''\n",
    "    Encode the variance from the priorbox layers inot the ground truth boxes \n",
    "    we have macthed  (based on jaccard overlap) with the prior boxes\n",
    "    Args:\n",
    "        matched:  (tensor) coords of ground truth for each prior in point_form \n",
    "                   shape = [num_priors, 4]\n",
    "       priors  : (tensor) priors boxes in center-offset form \n",
    "                   shape = [num_priors, 4]\n",
    "       variance: list(float) Variance of prior boxes\n",
    "\n",
    "    Returns:\n",
    "        encoded boxes: (tensor) shape = [num_priors, 4]\n",
    "    '''\n",
    "    # dist b/t match center and prior's center\n",
    "    g_cxcy = (matched[:, :2] + matched[:, 2:])/2 - priors[:, :2]\n",
    "    \n",
    "    # encode variance\n",
    "    g_cxcy /= (variances[0] * priors[:, 2:])\n",
    "    \n",
    "    # match wh / prior wh\n",
    "    g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:]\n",
    "    g_wh = np.log(g_wh) / variances[1]\n",
    "    \n",
    "    return np.concatenate((g_cxcy, g_wh), axis = 1)\n",
    "\n",
    "def encode_torch(matched, priors, variances):\n",
    "    \"\"\"Encode the variances from the priorbox layers into the ground truth boxes\n",
    "    we have matched (based on jaccard overlap) with the prior boxes.\n",
    "    Args:\n",
    "        matched: (tensor) Coords of ground truth for each prior in point-form\n",
    "            Shape: [num_priors, 4].\n",
    "        priors: (tensor) Prior boxes in center-offset form\n",
    "            Shape: [num_priors,4].\n",
    "        variances: (list[float]) Variances of priorboxes\n",
    "    Return:\n",
    "        encoded boxes (tensor), Shape: [num_priors, 4]\n",
    "    \"\"\"\n",
    "\n",
    "    # dist b/t match center and prior's center\n",
    "    g_cxcy = (matched[:, :2] + matched[:, 2:])/2 - priors[:, :2]\n",
    "    \n",
    "    # encode variance\n",
    "    g_cxcy /= (variances[0] * priors[:, 2:])\n",
    "    \n",
    "    # match wh / prior wh\n",
    "    g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:]\n",
    "    g_wh = torch.log(g_wh) / variances[1]\n",
    "    \n",
    "    # return target for smooth_l1_loss\n",
    "    return torch.cat([g_cxcy, g_wh], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_argmax(a, axis = 0):\n",
    "    \n",
    "    if not axis == 0:\n",
    "        raise ValueError('to be used only for axis 0')\n",
    "    \n",
    "    row, col = a.shape[:2]\n",
    "    output = []\n",
    "    for i in range(col):\n",
    "        x = a[:,i]\n",
    "        index = np.where(x == x.max(axis = 0))[0][-1] # the last entry in the array\n",
    "        output.append(index)\n",
    "        \n",
    "    return np.array(output)\n",
    "\n",
    "def index_fill(array, index, axis, value):\n",
    "    dim = array.shape\n",
    "    \n",
    "    if axis == 1:\n",
    "        for i in range(dim[0]):\n",
    "            np.put(array[i,:], index, value)\n",
    "            \n",
    "    elif axis == 0:\n",
    "        for i in range(dim[1]):\n",
    "            np.put(array[:,i], index, value)\n",
    "            \n",
    "    return array\n",
    "\n",
    "def match_np(truths      = None, \n",
    "          labels     = None, \n",
    "          priors     = None, \n",
    "          variance   = None, \n",
    "          threshold  = 0.5,\n",
    "        ):\n",
    "\n",
    "    \n",
    "    iou = jac_np(truths, priors)\n",
    "    \n",
    "    best_prior_overlap = np.amax(iou, axis=-1).astype(np.float32)\n",
    "    best_prior_idx     = np.argmax(iou, axis =-1)\n",
    "    \n",
    "# #    print(best_prior_overlap.shape)\n",
    "# #    print(best_prior_idx.shape)\n",
    "\n",
    "    best_truth_overlap = np.amax(iou, axis=0).astype(np.float32)\n",
    "    best_truth_idx     = numpy_argmax(iou)\n",
    "    \n",
    "    np.put(a= best_truth_overlap, ind = best_prior_idx, v=2)\n",
    "# #    print(best_truth_overlap.shape)\n",
    "# #    print(best_truth_idx.shape)\n",
    "\n",
    "    for j in range(best_prior_idx.shape[0]):\n",
    "        best_truth_idx[best_prior_idx[j]] = j\n",
    "    \n",
    "    matches = truths[best_truth_idx]\n",
    "    \n",
    "    conf    = labels[best_truth_idx]\n",
    "    conf[best_truth_overlap < threshold] = 0\n",
    "    \n",
    "    loc     = encode_np(matched=matches, priors=priors, variances=variance)\n",
    "    \n",
    "    return loc,conf\n",
    "\n",
    "\n",
    "def match_torch(threshold = 0.5, \n",
    "                truths = None, \n",
    "                priors = None, \n",
    "                variances = [0.1, 0.2], \n",
    "                labels = None):\n",
    "    \n",
    "    overlaps = jac_torch(truths, priors)\n",
    "    \n",
    "    # (Bipartite Matching)\n",
    "    # [1,num_objects] best prior for each ground truth\n",
    "    best_prior_overlap, best_prior_idx = overlaps.max(1, keepdim=True)\n",
    "#     # [1,num_priors] best ground truth for each prior\n",
    "    best_truth_overlap, best_truth_idx = overlaps.max(0, keepdim=True)\n",
    "    \n",
    "    best_truth_idx.squeeze_(0)\n",
    "    best_truth_overlap.squeeze_(0)\n",
    "    best_prior_idx.squeeze_(1)\n",
    "    best_prior_overlap.squeeze_(1)\n",
    "    \n",
    "    best_truth_overlap.index_fill_(0, best_prior_idx, 2)  # ensure best prior\n",
    "    \n",
    "    # TODO refactor: index  best_prior_idx with long tensor\n",
    "    # ensure every gt matches with its prior of max overlap\n",
    "    for j in range(best_prior_idx.size(0)):\n",
    "        best_truth_idx[best_prior_idx[j]] = j\n",
    "        \n",
    "    matches = truths[best_truth_idx]          # Shape: [num_priors,4]\n",
    "    \n",
    "    conf = labels[best_truth_idx]             # Shape: [num_priors]\n",
    "    conf[best_truth_overlap < threshold] = 0  # label as background\n",
    "    loc = encode_torch(matches, priors, variances)\n",
    "\n",
    "    return  loc, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_np, conf_np  = match_np(truths=loc_data_np, priors=priors_np, threshold=0.5, variance=[0.1,0.2], labels=conf_data)\n",
    "loc_th, conf_th  = match_torch(truths=loc_data_th_pf, priors=priors_th, threshold=0.5, labels=conf_data_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (loc_np == loc_th.numpy())\n",
    "np.sum(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_np(loc = None, priors=None, variances = [0.1, 0.2]):\n",
    "   \n",
    "    boxes = np.concatenate((\n",
    "        priors[:, :2] + loc[:, :2] * variances[0] * priors[:, 2:],\n",
    "        priors[:, 2:] * np.exp(loc[:, 2:] * variances[1])), axis = 1)\n",
    "    \n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2\n",
    "    boxes[:, 2:] += boxes[:, :2]\n",
    "    return boxes\n",
    "\n",
    "def decode_torch(loc, priors, variances):\n",
    "    \"\"\"Decode locations from predictions using priors to undo\n",
    "    the encoding we did for offset regression at train time.\n",
    "    Args:\n",
    "        loc (tensor): location predictions for loc layers,\n",
    "            Shape: [num_priors,4]\n",
    "        priors (tensor): Prior boxes in center-offset form.\n",
    "            Shape: [num_priors,4].\n",
    "        variances: (list[float]) Variances of priorboxes\n",
    "    Return:\n",
    "        decoded bounding box predictions\n",
    "    \"\"\"\n",
    "\n",
    "    boxes = torch.cat((\n",
    "        priors[:, :2] + loc[:, :2] * variances[0] * priors[:, 2:],\n",
    "        priors[:, 2:] * torch.exp(loc[:, 2:] * variances[1])), 1)\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2\n",
    "    boxes[:, 2:] += boxes[:, :2]\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_np = decode_np(loc= loc_np, priors=priors_np, variances=[0.1, 0.2])\n",
    "boxes_th = decode_torch(loc=loc_th, priors=priors_th, variances=[0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (boxes_np == boxes_th.numpy())\n",
    "np.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
